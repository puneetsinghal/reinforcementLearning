{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import mpld3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "mpld3.enable_notebook()\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "from colorsys import hsv_to_rgb\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class incrementalOffPolicy(object):\n",
    "    def __init__(self, filename):\n",
    "        actualMap = np.array(self.txt_to_obs_map('track1.txt'))\n",
    "        reviseMap = np.empty(actualMap.shape)\n",
    "        for i in range(0,len(actualMap)):\n",
    "            reviseMap[i,] = actualMap[len(actualMap)-1-i,]\n",
    "        self.map = copy.copy(np.transpose(reviseMap))\n",
    "        \n",
    "        self.start = np.empty([1,2],dtype=int)\n",
    "        for i in range(0, self.map.shape[0]):\n",
    "            if self.map[i,0] == 0:\n",
    "                self.start = np.vstack((self.start,(i,0)))\n",
    "        self.start = np.delete(self.start,(0), axis=0)\n",
    "        \n",
    "        self.finish = np.empty([1,2])\n",
    "        for i in range(0, self.map.shape[1]):\n",
    "            if self.map[self.map.shape[0]-1,i] == 0:\n",
    "                self.finish = np.vstack((self.finish,(self.map.shape[0]-1,i)))\n",
    "        self.finish = np.delete(self.finish, (0), axis=0)\n",
    "        \n",
    "        self.epsilon = 1\n",
    "        self.initialVelocity = [0,0]\n",
    "        self.allActions = np.array(((-1,-1), (-1,0), (-1,1), \n",
    "                                        (0,-1), (0,0), (0,1),\n",
    "                                        (1,-1), (1,0), (1,1)))\n",
    "        self.maxVelocity = 5\n",
    "        self.minVelocity = 0\n",
    "        self.numStates = self.map.size*(self.maxVelocity - self.minVelocity + 1)**2\n",
    "        self.numActions = len(self.allActions)\n",
    "        try:\n",
    "            self.Q = np.random.rand(self.numStates,self.numActions)\n",
    "#             self.Q = np.loadtxt('newq_2050000.txt')\n",
    "        except:\n",
    "            self.Q = np.empty(shape=(self.numStates,self.numActions))\n",
    "\n",
    "        self.C = np.zeros(shape=(self.numStates,self.numActions))\n",
    "        self.finishState = np.empty(shape=(1,4))\n",
    "\n",
    "    def txt_to_obs_map(self, file_name):\n",
    "        with open(file_name) as inputFile:\n",
    "            return [[int(i) for i in line.strip().split('\\t')] for line in inputFile]\n",
    "\n",
    "    def behaviourPolicy(self):\n",
    "        return np.random.randint(9)\n",
    "\n",
    "    def targetPolicy1(self, previousState):\n",
    "        if(previousState[1] ==0):\n",
    "            xVel = 0\n",
    "            yVel = 1\n",
    "        elif (previousState[1] < 28):\n",
    "            if(previousState[3] == 0):\n",
    "                xVel = 0\n",
    "                yVel = 1\n",
    "            else:\n",
    "                xVel = 0\n",
    "                yVel = 0\n",
    "        elif(previousState[1] >= 28):\n",
    "            xVel = 1\n",
    "            if(previousState[3] == 0):\n",
    "                yVel = 0\n",
    "            else:\n",
    "                yVel = -1\n",
    "        return np.array((xVel, yVel))\n",
    "    \n",
    "    def uniformTargetPolicy(self):\n",
    "        policy = np.zeros(self.Q.shape)\n",
    "        for i in range(0, self.Q.shape[0]):\n",
    "            state = self.statesIndex2states(i)\n",
    "            possibleActions = self.possibleActions(state[2], state[3])\n",
    "            numPossibleActions = np.sum(possibleActions)\n",
    "            policy[i] = 1.0*possibleActions/numPossibleActions\n",
    "#         policy = np.random.uniform(0,1,(self.map.size*6*6,9))\n",
    "#         for i in range(0, policy.shape[0]):\n",
    "#             policy[i] = policy[i]/LA.norm(policy[i])\n",
    "        return policy\n",
    "    \n",
    "    def greedyTargetPolicy(self, policy, episode):\n",
    "        for i in range(0, episode.shape[0]):\n",
    "            stateIndex = self.stateIndex(episode[i])\n",
    "            state = copy.copy(self.statesIndex2states(stateIndex))\n",
    "            possibleActions = self.possibleActions(state[2], state[3])\n",
    "            numPossibleActions = np.sum(possibleActions)\n",
    "            possibleActionsBool = possibleActions == 1\n",
    "            maxQ = np.amax(self.Q[stateIndex, possibleActionsBool])\n",
    "            for j in range(0,len(possibleActions)):\n",
    "                if possibleActions[j] == 1:\n",
    "                    if self.Q[stateIndex,j] == maxQ:\n",
    "                        policy[stateIndex,j] = 1 - self.epsilon + self.epsilon/numPossibleActions\n",
    "                    else:\n",
    "                        policy[stateIndex,j] = self.epsilon/numPossibleActions\n",
    "        return policy\n",
    "    \n",
    "    def updateTargetPolicy(self, policy, state):\n",
    "        stateIndex = self.stateIndex(state)\n",
    "        possibleActions = self.possibleActions(state[2], state[3])\n",
    "        numPossibleActions = np.sum(possibleActions)\n",
    "        if numPossibleActions==0:\n",
    "            print(\"error: \", possibleActions)\n",
    "        possibleActionsBool = possibleActions == 1\n",
    "        maxQ = np.amax(self.Q[stateIndex, possibleActionsBool])\n",
    "        greedyActions = self.Q[stateIndex,possibleActionsBool] == maxQ\n",
    "        numGreedyActions = sum(greedyActions)\n",
    "        for j in range(0,len(possibleActions)):\n",
    "            policy[stateIndex,j] = 0\n",
    "            if possibleActions[j] == 1:\n",
    "                if self.Q[stateIndex,j] == maxQ:\n",
    "                    policy[stateIndex,j] = (1.0 - self.epsilon)/numGreedyActions + self.epsilon/numPossibleActions\n",
    "                else:\n",
    "                    policy[stateIndex,j] = self.epsilon/numPossibleActions\n",
    "        if np.sum(policy[stateIndex]) > 1.001 or np.sum(policy[stateIndex]) < 0.998:\n",
    "            print(possibleActions)\n",
    "            print(self.Q[stateIndex])\n",
    "            print(possibleActionsBool,maxQ)\n",
    "            print(\"state: \", state)\n",
    "            print(\"policy: \", policy[stateIndex])\n",
    "            print(\"gredyActions: \",greedyActions)\n",
    "        return policy\n",
    "    \n",
    "    def possibleActions(self, velocity_x, velocity_y):\n",
    "        possibleActions = np.ones(self.numActions)\n",
    "#         print(possibleActions)\n",
    "        for j in range(0, self.numActions):\n",
    "            projVelocityX = velocity_x + self.allActions[j,0]\n",
    "            projVelocityY = velocity_y + self.allActions[j,1]\n",
    "            # print(projVelocityX, projVelocityY, self.allActions[j])\n",
    "            if (projVelocityX>=self.minVelocity and projVelocityX<=self.maxVelocity and \n",
    "                projVelocityY>=self.minVelocity and projVelocityY<=self.maxVelocity):\n",
    "                if projVelocityX==self.minVelocity and projVelocityY==self.minVelocity:\n",
    "                    possibleActions[j] = 0\n",
    "                else:\n",
    "                    possibleActions[j] = 1\n",
    "            else:\n",
    "                possibleActions[j] = 0\n",
    "#         print(possibleActions)\n",
    "        return possibleActions\n",
    "\n",
    "    def generateEpisode(self, policy):\n",
    "        # print(self.start, self.start.shape)\n",
    "        previousState = np.append(self.start[np.random.randint(self.start.shape[0])], [0,0])\n",
    "        episode = np.zeros(shape=(1,6))\n",
    "        while True:\n",
    "            stateIndex = self.stateIndex(previousState)\n",
    "            temp = copy.copy(policy[stateIndex])\n",
    "#             print(stateIndex, temp, np.sum(temp))\n",
    "            actionIndex = np.random.choice(9,1, p=temp.tolist())\n",
    "            action = copy.copy(self.allActions[actionIndex])\n",
    "            velocity_x = max(min((previousState[2]+action[0,0]),5),0)\n",
    "            velocity_y = max(min((previousState[3]+action[0,1]),5),0)\n",
    "            nextState = np.array(((previousState[0] + velocity_x),\n",
    "                                    (previousState[1] + velocity_y), velocity_x, velocity_y))\n",
    "            nextState = nextState.astype(int)\n",
    "            intersection = self.projectedIntersection(previousState, nextState)\n",
    "            if (intersection == 2):\n",
    "                nextState = np.append(copy.copy(\n",
    "                    self.start[np.random.randint(self.start.shape[0])]), [0,0])\n",
    "#                 self.finishState[0,2] = copy.copy(velocity_x)\n",
    "#                 self.finishState[0,3] = copy.copy(velocity_y)\n",
    "                reward = -1\n",
    "#                 break\n",
    "            elif (intersection == 1):\n",
    "                # episode = np.vstack((episode, np.append(nextState,np.array((0, action[0], action[1])))))\n",
    "                self.finishState[0,2] = copy.copy(velocity_x)\n",
    "                self.finishState[0,3] = copy.copy(velocity_y)\n",
    "                break\n",
    "            else:\n",
    "                reward = -1\n",
    "                \n",
    "#             print(np.append(previousState,[reward, actionIndex]), episode.shape, stateIndex)\n",
    "\n",
    "            if episode.shape[0] == 1:\n",
    "                episode = np.append(previousState, [reward, actionIndex])\n",
    "            else:\n",
    "                episode = np.vstack((episode, np.append(previousState, [reward, actionIndex])))\n",
    "            previousState = copy.copy(nextState)\n",
    "            \n",
    "#         print(np.append(previousState, [reward, actionIndex]), episode.shape)\n",
    "        episode = np.vstack((episode, np.append(previousState, [reward, actionIndex])))\n",
    "#         print(np.append(previousState,np.array((reward, actionIndex))))\n",
    "        episode =np.vstack((episode, np.append(self.finishState, [reward, actionIndex])))\n",
    "        return episode\n",
    "\n",
    "    def projectedIntersection(self, previousState, nextState):\n",
    "        projectedState = copy.copy(previousState[0:2])\n",
    "#         print(projectedState)\n",
    "        for i in range(0, max(nextState[2], nextState[3])+1):\n",
    "            if(np.amin(np.sum(np.absolute(self.finish - np.array(projectedState[0:2])),axis=1)) ==0):\n",
    "                self.finishState[0,0] = copy.copy(projectedState[0])\n",
    "                self.finishState[0,1] = copy.copy(projectedState[1])\n",
    "                return 1\n",
    "            if(projectedState[0] >= self.map.shape[0]-1 or projectedState[1] >= self.map.shape[1]-1 or \n",
    "               self.map[projectedState[0],projectedState[1]] == 1):\n",
    "                self.finishState[0,0] = copy.copy(projectedState[0])\n",
    "                self.finishState[0,1] = copy.copy(projectedState[1])\n",
    "                return 2\n",
    "#             elif(self.map[projectedState[0],projectedState[1]] == 1):\n",
    "#                 return 2\n",
    "            projectedState[0] = min(projectedState[0]+1,nextState[0])\n",
    "            projectedState[1] = min(projectedState[1]+1,nextState[1])\n",
    "        return 3\n",
    "    \n",
    "    def stateIndex(self, currentState):\n",
    "        velRange = (self.maxVelocity - self.minVelocity + 1)\n",
    "        return int((velRange**2)*(currentState[1]*self.map.shape[0] + currentState[0]) + 6*currentState[3] + currentState[2] )\n",
    "    \n",
    "    def statesIndex2states(self, stateIndex):\n",
    "        velRange = (mc.maxVelocity - mc.minVelocity + 1)\n",
    "        velocity_x = (stateIndex%(velRange**2))%velRange\n",
    "        velocity_y = (stateIndex%(velRange**2))/velRange\n",
    "        stateY = int(int(stateIndex/velRange**2)/mc.map.shape[0])\n",
    "        stateX = int(int(stateIndex/velRange**2)%mc.map.shape[0])\n",
    "        return np.array((stateX, stateY, velocity_x, velocity_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mc = incrementalOffPolicy(filename = 'track1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gamma = 1.\n",
    "count = 0\n",
    "policyPI = mc.uniformTargetPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt: 25100 otherC: 110   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 25200 otherC: 230   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 25300 otherC: 567   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 25400 otherC: 469   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 25500 otherC: 229   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 25600 otherC: 192   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 25700 otherC: 708   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 25800 otherC: 357   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 25900 otherC: 185   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 26000 otherC: 688   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 26100 otherC: 181   state: [ 3.  0.  0.  0. -1.  7.]\n",
      "cnt: 26200 otherC: 290   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 26300 otherC: 215   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 26400 otherC: 60   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 26500 otherC: 198   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 26600 otherC: 175   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 26700 otherC: 12   state: [ 5.  0.  0.  0. -1.  5.]\n",
      "cnt: 26800 otherC: 770   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 26900 otherC: 204   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 27000 otherC: 314   state: [ 6.  0.  0.  0. -1.  5.]\n",
      "cnt: 27100 otherC: 554   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 27200 otherC: 861   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 27300 otherC: 63   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 27400 otherC: 215   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 27500 otherC: 56   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 27600 otherC: 529   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 27700 otherC: 604   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 27800 otherC: 391   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 27900 otherC: 175   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 28000 otherC: 160   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 28100 otherC: 346   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 28200 otherC: 85   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 28300 otherC: 430   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 28400 otherC: 461   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 28500 otherC: 325   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 28600 otherC: 15   state: [ 3.  0.  0.  0. -1.  5.]\n",
      "cnt: 28700 otherC: 198   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 28800 otherC: 61   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 28900 otherC: 461   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29000 otherC: 96   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 29100 otherC: 399   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29200 otherC: 497   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 29300 otherC: 134   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29400 otherC: 209   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29500 otherC: 88   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 29600 otherC: 36   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29700 otherC: 340   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29800 otherC: 133   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 29900 otherC: 109   state: [ 6.  0.  0.  0. -1.  5.]\n",
      "cnt: 30000 otherC: 69   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 30100 otherC: 333   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 30200 otherC: 64   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 30300 otherC: 525   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 30400 otherC: 41   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 30500 otherC: 365   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 30600 otherC: 129   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 30700 otherC: 675   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 30800 otherC: 23   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 30900 otherC: 895   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 31000 otherC: 461   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 31100 otherC: 277   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 31200 otherC: 423   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 31300 otherC: 493   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 31400 otherC: 814   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 31500 otherC: 279   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 31600 otherC: 153   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 31700 otherC: 76   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 31800 otherC: 47   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 31900 otherC: 33   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 32000 otherC: 485   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 32100 otherC: 43   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 32200 otherC: 921   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 32300 otherC: 46   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 32400 otherC: 342   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 32500 otherC: 892   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 32600 otherC: 58   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 32700 otherC: 203   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 32800 otherC: 478   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 32900 otherC: 261   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 33000 otherC: 392   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 33100 otherC: 28   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 33200 otherC: 85   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 33300 otherC: 298   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 33400 otherC: 61   state: [ 4.  0.  0.  0. -1.  5.]\n",
      "cnt: 33500 otherC: 218   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 33600 otherC: 120   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 33700 otherC: 139   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 33800 otherC: 773   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 33900 otherC: 836   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 34000 otherC: 173   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 34100 otherC: 192   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 34200 otherC: 1028   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 34300 otherC: 107   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 34400 otherC: 391   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 34500 otherC: 205   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 34600 otherC: 105   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 34700 otherC: 133   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 34800 otherC: 320   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 34900 otherC: 264   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 35000 otherC: 269   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 35100 otherC: 135   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 35200 otherC: 835   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 35300 otherC: 120   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 35400 otherC: 466   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 35500 otherC: 279   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 35600 otherC: 686   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 35700 otherC: 525   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 35800 otherC: 304   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 35900 otherC: 259   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 36000 otherC: 1341   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 36100 otherC: 813   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 36200 otherC: 377   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 36300 otherC: 269   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 36400 otherC: 209   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 36500 otherC: 128   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 36600 otherC: 487   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 36700 otherC: 381   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 36800 otherC: 244   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 36900 otherC: 281   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 37000 otherC: 18   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 37100 otherC: 38   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 37200 otherC: 42   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 37300 otherC: 329   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 37400 otherC: 914   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 37500 otherC: 137   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 37600 otherC: 113   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 37700 otherC: 61   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 37800 otherC: 459   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 37900 otherC: 219   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 38000 otherC: 186   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 38100 otherC: 292   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 38200 otherC: 222   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 38300 otherC: 803   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 38400 otherC: 20   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 38500 otherC: 72   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 38600 otherC: 626   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 38700 otherC: 275   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 38800 otherC: 137   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 38900 otherC: 106   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 39000 otherC: 180   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 39100 otherC: 121   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 39200 otherC: 43   state: [ 5.  0.  0.  0. -1.  8.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt: 39300 otherC: 1375   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 39400 otherC: 91   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 39500 otherC: 509   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 39600 otherC: 65   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 39700 otherC: 42   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 39800 otherC: 322   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 39900 otherC: 287   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 40000 otherC: 827   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 40100 otherC: 316   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 40200 otherC: 191   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 40300 otherC: 350   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 40400 otherC: 180   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 40500 otherC: 110   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 40600 otherC: 93   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 40700 otherC: 225   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 40800 otherC: 125   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 40900 otherC: 163   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 41000 otherC: 487   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 41100 otherC: 591   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 41200 otherC: 151   state: [ 4.  0.  0.  0. -1.  5.]\n",
      "cnt: 41300 otherC: 32   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 41400 otherC: 80   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 41500 otherC: 538   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 41600 otherC: 203   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 41700 otherC: 124   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 41800 otherC: 123   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 41900 otherC: 565   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 42000 otherC: 370   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 42100 otherC: 57   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 42200 otherC: 139   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 42300 otherC: 12   state: [ 5.  0.  0.  0. -1.  5.]\n",
      "cnt: 42400 otherC: 30   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 42500 otherC: 78   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 42600 otherC: 198   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 42700 otherC: 504   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 42800 otherC: 51   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 42900 otherC: 178   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 43000 otherC: 164   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 43100 otherC: 255   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 43200 otherC: 209   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 43300 otherC: 65   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 43400 otherC: 84   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 43500 otherC: 113   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 43600 otherC: 522   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 43700 otherC: 988   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 43800 otherC: 45   state: [ 6.  0.  0.  0. -1.  7.]\n",
      "cnt: 43900 otherC: 261   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 44000 otherC: 545   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 44100 otherC: 139   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 44200 otherC: 25   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 44300 otherC: 620   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 44400 otherC: 72   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 44500 otherC: 629   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 44600 otherC: 245   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 44700 otherC: 273   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 44800 otherC: 1240   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 44900 otherC: 561   state: [ 8.  0.  0.  0. -1.  8.]\n",
      "cnt: 45000 otherC: 136   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 45100 otherC: 107   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 45200 otherC: 50   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 45300 otherC: 367   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 45400 otherC: 1165   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 45500 otherC: 252   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 45600 otherC: 65   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 45700 otherC: 262   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 45800 otherC: 198   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 45900 otherC: 131   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 46000 otherC: 282   state: [ 6.  0.  0.  0. -1.  5.]\n",
      "cnt: 46100 otherC: 457   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 46200 otherC: 353   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 46300 otherC: 432   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 46400 otherC: 400   state: [ 5.  0.  0.  0. -1.  8.]\n",
      "cnt: 46500 otherC: 142   state: [ 3.  0.  0.  0. -1.  8.]\n",
      "cnt: 46600 otherC: 83   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 46700 otherC: 71   state: [ 6.  0.  0.  0. -1.  8.]\n",
      "cnt: 46800 otherC: 133   state: [ 4.  0.  0.  0. -1.  8.]\n",
      "cnt: 46900 otherC: 210   state: [ 7.  0.  0.  0. -1.  8.]\n",
      "cnt: 47000 otherC: 378   state: [ 6.  0.  0.  0. -1.  8.]\n"
     ]
    }
   ],
   "source": [
    "otherCount = 0\n",
    "while count <= 50000:\n",
    "    episode = mc.generateEpisode(policyPI)\n",
    "    # state : {x, y, vx, vy}\n",
    "    # action-value function q(every state): vector of 36*9 elements for every grid\n",
    "    G = 0.\n",
    "#         W = 1.\n",
    "    otherCount = 0\n",
    "    for i in range(episode.shape[0]-2, -1, -1):\n",
    "        state = copy.copy(episode[i])\n",
    "        G = gamma*G + episode[i,4]\n",
    "        ind1 = mc.stateIndex(episode[i])\n",
    "        ind2 =  int(copy.copy(episode[i,5]))\n",
    "        mc.C[ind1,ind2] += 1\n",
    "        mc.Q[ind1,ind2] = mc.Q[ind1,ind2] + (1./mc.C[ind1,ind2])*(G - mc.Q[ind1,ind2])\n",
    "#             W = W*policyPI[ind1,ind2]*np.sum(mc.possibleActions(state[2], state[3]))/np.sum(policyPI[ind1])\n",
    "        policyPI = mc.updateTargetPolicy(policyPI, state)\n",
    "        otherCount += 1\n",
    "#             print(\"cnt:\", count, \"otherC:\", otherCount,\"  state:\", state)\n",
    "    count += 1\n",
    "    if (count%500 ==0 and mc.epsilon >0.1):\n",
    "        mc.epsilon -= 0.05\n",
    "    if (count%100 == 0):\n",
    "        print(\"cnt:\", count, \"otherC:\", otherCount,\"  state:\", state)\n",
    "#     if (count % 1000 == 0):\n",
    "#         np.savetxt('oldq_%d.txt'% count, mc.Q, fmt='%.18e', delimiter=' ', newline='\\n')\n",
    "\n",
    "np.savetxt('oldQ.txt', mc.Q, fmt='%.18e', delimiter=' ', newline='\\n')\n",
    "np.savetxt('oldN.txt', mc.C, fmt='%.18e', delimiter=' ', newline='\\n')\n",
    "np.savetxt('oldPolicy.txt', policyPI, fmt='%.18e', delimiter=' ', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc.epsilon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hsv values for plotting 10 paths\n",
    "HSV_VALS = [[0.5574, 0.2687, 0.8902],\n",
    "            [0.6667, 1.0000, 1.0000],\n",
    "            [0.3333, 1.0000, 1.0000],\n",
    "            [0.1667, 1.0000, 1.0000],\n",
    "            [0.0017, 0.3904, 0.9843],\n",
    "            [0.0939, 0.5613, 0.9922],\n",
    "            [0.0830, 1.0000, 1.0000],\n",
    "            [0.7778, 0.1682, 0.8392],\n",
    "            [0.7473, 0.6039, 0.6039],\n",
    "            [0.0596, 0.7740, 0.6941]]\n",
    "\n",
    "# offset so colors aren't too light\n",
    "OFFSET = 25\n",
    "\n",
    "def colorize_path(track, path, save_location):\n",
    "    newTrack = np.zeros\n",
    "    path_map = np.uint8((np.array(track) == 0) * 255)\n",
    "    (h,w) = path_map.shape\n",
    "    path_map = np.repeat(path_map,3).reshape((h,w,3))\n",
    "\n",
    "    for i in range(0,path.shape[0]):\n",
    "        (x, y) = path[i]\n",
    "#         print(x,y)\n",
    "        path_map[int(x),int(y)] = [int(a * 255) for a in hsv_to_rgb(HSV_VALS[0][0],float(i+OFFSET)/(path.shape[0]+OFFSET) * HSV_VALS[0][1],HSV_VALS[0][2])]\n",
    "#         comp_path = [path_elem for path_elem in path[i] if path_elem is not None]\n",
    "#         duplicates = set([a for a in comp_path if comp_path.count(a) > 1])\n",
    "#         if len(duplicates) > 0:\n",
    "#             for (r,c) in duplicates:\n",
    "#                 path_map[r,c] = [255,0,0] # red color for collisions\n",
    "#                 print(\"collision at:\", (r,c))\n",
    "    im = Image.fromarray(path_map, 'RGB')\n",
    "    im.save(save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-aa0e5a460981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mepisode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreviousState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mepisode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreviousState\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactionIndex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mpreviousState\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnextState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# mc = incrementalOffPolicy(filename = 'track1.txt')\n",
    "# mc.Q = np.loadtxt('oldQ.txt')\n",
    "# policyPI = np.loadtxt('oldPolicy.txt')\n",
    "previousState = np.append(mc.start[np.random.randint(mc.start.shape[0])], [0,0])\n",
    "# previousState = np.append(mc.start[2],(0, 0))\n",
    "stateInd = 1\n",
    "episode = np.zeros(shape=(1,7))\n",
    "while True:\n",
    "    stateIndex = mc.stateIndex(previousState)\n",
    "    temp = copy.copy(policyPI[stateIndex])\n",
    "#             print(stateIndex, temp, np.sum(temp))\n",
    "    actionIndex = np.random.choice(9,1, p=temp.tolist())[0]\n",
    "#     actionIndex = np.argmax(mc.Q[stateIndex])\n",
    "    action = copy.copy(mc.allActions[actionIndex])\n",
    "#     print(action)\n",
    "    velocity_x = max(min((previousState[2]+action[0]),5),0)\n",
    "    velocity_y = max(min((previousState[3]+action[1]),5),0)\n",
    "    nextState = np.array(((previousState[0] + velocity_x),\n",
    "                            (previousState[1] + velocity_y), velocity_x, velocity_y))\n",
    "    nextState = nextState.astype(int)\n",
    "    intersection = mc.projectedIntersection(previousState, nextState)\n",
    "    if (intersection == 2):\n",
    "        nextState = np.append(copy.copy(\n",
    "                        mc.start[np.random.randint(mc.start.shape[0])]), [0,0])\n",
    "#         mc.finishState[0,2] = copy.copy(velocity_x)\n",
    "#         mc.finishState[0,3] = copy.copy(velocity_y)\n",
    "        reward = -1\n",
    "#         break\n",
    "    elif (intersection == 1):\n",
    "        # episode = np.vstack((episode, np.append(nextState,np.array((0, action[0], action[1])))))\n",
    "        mc.finishState[0,2] = copy.copy(velocity_x)\n",
    "        mc.finishState[0,3] = copy.copy(velocity_y)\n",
    "        break\n",
    "    else:\n",
    "        reward = -1\n",
    "\n",
    "#     print(np.append(previousState,[reward, actionIndex]), episode.shape, stateIndex)\n",
    "\n",
    "    if episode.shape[0] == 1:\n",
    "        episode = np.append(previousState, [reward, actionIndex])\n",
    "    else:\n",
    "        episode = np.vstack((episode, np.append(previousState, [reward, actionIndex])))\n",
    "    previousState = copy.copy(nextState)\n",
    "            \n",
    "print(np.append(previousState, [reward, actionIndex]), episode.shape)\n",
    "episode = np.vstack((episode, np.append(previousState, [reward, actionIndex])))\n",
    "print(np.append(previousState,np.array((reward, actionIndex))))\n",
    "episode =np.vstack((episode, np.append(mc.finishState, [reward, actionIndex])))\n",
    "path = copy.copy(episode[:,0:2])\n",
    "print(\"steps: \", path.shape[0], \"totalReard: \", sum(episode[:,4]))\n",
    "colorize_path(mc.map, path, \"path.png\")\n",
    "# IM(filename='path.png')\n",
    "img=mpimg.imread('path.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
